###############################################################################
# Workflow configuration file and documentation for ConMan
# © Tom Rainsford, Institut für Linguistik/Romanistik, 2022-
###############################################################################


###############################################################################
# The default section is used to select up to four objects that are required  #
# for the conversion:                                                         #
# - importer : selects the class of importer from conman.importers to use     #
#              for the conversion. If not given, ConMan will attempt to       #
#              use the file extension and will IGNORE the importer sections   # 
#              of this config file.                                           #
# - other_importer :                                                          # 
#              selects the class of importer from conman.importers to use     #
#              loading the concordance to be merged. If not given, ConMan     # 
#              will attempt to use the file extension and will IGNORE the     #
#              other_importer section of this config file.                    #
# - exporter : selects the class of exporter from conman.exporters to use for #
#              the conversion. If not given, ConMan will attempt to use the   #
#              file extension and will IGNORE the exporter section of         #
#              this config file.                                              #
###############################################################################
[DEFAULT]
importer=PennOutImporter
other_importer=
exporter=TableExporter

###############################################################################
# The Importer section contains all parameters used to configure the          # 
# concordance importer. Settings are only applied if an importer is set in    #
# the DEFAULT section above.                                                  #
#                                                                             #
# Settings related to parsing Tokens (all importers):                         #
# ---------------------------------------------------                         #
# lcx_regex, keywds_regex, rcx_regex:                                         #
# 		Python 3 regex patterns which are used to interpret strings           # 
#       representing the token and eventual tags in the left context,         #
#       the keywords, and the right context respectively. The pattern must    #
#       use symbolic group names using the '(?P<name>...)' operator, and one  #
#       of those groups must be called "word". Other groups are interpreted   #
#       as tags. So, for instance, for token strings in "word_lemma" format,  #
#       the regex should be set to '(?P<word>[^_]+)_(?P<lemma>.*)'.           #
#       Where the tokens are not split into keywords and context, the regex   #
#       in lcx_regex is applied to ALL tokens.                                #
# ref_regex:                                                                  #
# 		Python 3 regex pattern used to parse the reference for a hit in the   #
#       concordance and split it into fields. The field names are defined     #
#       using symbolic group names (see above). If not given, importer will   #
#       not attempt to interpret the fields in the reference string.          #
# tokenizer:                                                                  #
#       Selects the tokenizer from conman.tokenizers to be used to tokenize   #
#       the hit. If not passed, defaults to Tokenizer and uses whitespace,    #
#       ignoring all settings in the tokenizer section of this file.          #
#       Also ignored by importers for formats which are already tokenized.    #
#                                                                             #
###############################################################################


[importer]
lcx_regex="(?P<word>.+)@l=(?P<lemma>.*)"
keywds_regex=
rcx_regex=
ref_regex=
tokenizer=




[exporter]

[other_importer]

[merger]

