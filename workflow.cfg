###############################################################################
# Workflow configuration file and documentation for ConMan
# © Tom Rainsford, Institut für Linguistik/Romanistik, 2022-
###############################################################################


###############################################################################
# The default section is used to select up to four objects that are required  #
# for the conversion:                                                         #
# - importer : selects the class of importer from conman.importers to use     #
#              for the conversion. If not given, ConMan will attempt to       #
#              use the file extension and will IGNORE the importer sections   # 
#              of this config file.                                           #
# - other_importer :                                                          # 
#              selects the class of importer from conman.importers to use     #
#              loading the concordance to be merged. If not given, ConMan     # 
#              will attempt to use the file extension and will IGNORE the     #
#              other_importer section of this config file.                    #
# - exporter : selects the class of exporter from conman.exporters to use for #
#              the conversion. If not given, ConMan will attempt to use the   #
#              file extension and will IGNORE the exporter section of         #
#              this config file.                                              #
###############################################################################
[DEFAULT]
importer=PennOutImporter
other_importer=
exporter=TableExporter

###############################################################################
# The importer and other_importer sections contains all parameters used to    #
# configure the concordance importer. Settings are only applied if an         #
# importer is set in the DEFAULT section above.                               # 
#                                                                             #
# Settings related to parsing Tokens (all importers):                         #
# ---------------------------------------------------                         #
# lcx_regex, keywds_regex, rcx_regex:                                         #
#       Python 3 regex patterns which are used to interpret strings           # 
#       representing the token and eventual tags in the left context,         #
#       the keywords, and the right context respectively. The pattern must    #
#       use symbolic group names using the '(?P<name>...)' operator, and one  #
#       of those groups must be called "word". Other groups are interpreted   #
#       as tags. So, for instance, for token strings in "word_lemma" format,  #
#       the regex should be set to '(?P<word>[^_]+)_(?P<lemma>.*)'.           #
#       Where the tokens are not split into keywords and context, the regex   #
#       in lcx_regex is applied to ALL tokens.                                #
# ref_regex:                                                                  #
#       Python 3 regex pattern used to parse the reference for a hit in the   #
#       concordance and split it into fields. The field names are defined     #
#       using symbolic group names (see above). If not given, importer will   #
#       not attempt to interpret the fields in the reference string.          #
# tokenizer:                                                                  #
#       Selects the tokenizer from conman.tokenizers to be used to tokenize   #
#       the hit. If not passed, defaults to Tokenizer and uses whitespace,    #
#       ignoring all settings in the tokenizer section of this file.          #
#       Also ignored by importers for formats which are already tokenized.    #
#                                                                             #
# Settings for TableImporter (CSV files)                                      #
# --------------------------------------                                      #
# TI_dialect:                                                                 #
#        Dialect to use for the CSV reader. Default: 'excel'. Options are:    #
#       'excel':    Comma-separated, quote with " only when necessary.        #
#        'tab'  :    Tab-separated, no quoting or escaping.                   #
# TI_has_header:                                                              #
#       File has a header row if set to 'True'. Default is True.              #
# TI_fields:                                                                  #
#       Comma-separated list of fields to import in the order in which the    #
#       columns are found in the file. If set, it overrides fieldnames read   #
#       from the header row. The following fieldnames IN CAPITALS must be     #
#       used for the correct import of fields containing the tokens and       #
#       references.                                                           #
#               KEYWORDS:   Keyword tokens only                               #
#               LCX:        Tokens preceding keywords only                    #
#               RCX:        Tokens following keywords only                    #
#               REF:        Reference                                         #
#               TOKENS:     Tokens, if not divided into keywords/context      #
#       Additionally, concordances exported by ConMan can contain the special #
#       field "UUID". This field can be re-imported using the fieldname       # 
#       "UUID" but values should not be modified.                             #
#                                                                             #
# Settings for BaseTreeImporter                                               #
# -------------------------------------------------------------------         #
# BT_keyword_attr:                                                            #
#       Name of the XML attribute which indicates whether the token is a      #
#       keyword or not. Value must be 'yes', 'y', 't' or 'true' (not          # 
#       case-sensitive). If not given, no keywords are identified.            #
#       DO NOT set this if using the PennOutImporter!                         # 
#                                                                             #
# Settings for PennOutImporter                                                #
# ----------------------------                                                #
# PO_keyword_node_regex:                                                      #
#       Python 3 regex used to identify the node number of the keyword node   #
#       from the comment above the tree. The matching node must be identified #
#       by the symbolic group name 'keyword_node'.                            #
#       Default is r'[^0-9]*(?P<keyword_node>[0-9]+)[^0-9]+.*', i.e. the first#
#       number in the comment (typically the dominating IP).                  #
#                                                                             # 
###############################################################################

[importer]
lcx_regex=(?P<word>.*)
keywds_regex=(?P<word>.*)
rcx_regex=(?P<word>.*)
TI_dialect=excel
TI_has_header=True
TI_fields=REF,LCX,KEYWORDS,RCX
PO_keyword_node_regex="[^0-9]*(?P<keyword_node>[0-9]+)[^0-9]+.*"

[other_importer]
lcx_regex=(?P<word>.*)
keywds_regex=(?P<word>.*)
rcx_regex=(?P<word>.*)
TI_dialect=excel
TI_has_header=True
TI_fields=REF,LCX,KEYWORDS,RCX
PO_keyword_node_regex=[^0-9]*(?P<keyword_node>[0-9]+)[^0-9]+.*

###############################################################################
# The exporter section contains all parameters used to                        #
# configure the concordance exporter. Settings are only applied if an         #
# exporter is set in the DEFAULT section above.                               # 
#                                                                             #
# Settings related to representing Tokens (all exporters):                    #
# --------------------------------------------------------                    #
# tok_fmt:                                                                    #
#       Format string used to represent each token. Takes a single positional #
#       argument, which is evaluated as a token instance. Default is '{0}',   #
#       i.e. just the token as a string.                                      #                                        
#                                                                             #
# kw_fmt:                                                                     #
#       Format string used to represent each keyword token. Takes a single    #
#       positional argument, which is evaluated as a token instance. Annotation 
#       is accessible using {0.tags[name_of_tag]}. If not passed, uses        #
#       tok_fmt.                                                              #
#                                                                             #
# tok_delimiter:                                                              #
#       String used to delimit the tokens. Default is ' '. Tip: pass '\n' for # 
#       simple one-token-per-line formats.                                    #
#                                                                             #
# Settings related to the TableExporter                                       #
# -------------------------------------                                       #
# TE_dialect:                                                                 #
#       Dialect to use for the CSV writer. Default: 'excel'. Options are:     #
#       'excel':    Comma-separated, quote with " only when necessary.        #
#       'tab'  :    Tab-separated, no quoting or escaping.                    #
#                                                                             #
# TE_header:                                                                  #
#       Write a header row if set to "True". Default is True.                 #
#                                                                             #
# TE_fields:                                                                  #
#       Comma-separated list of fields to export in the order in which the    #
#       columns are found in the file. The following fieldnames IN CAPITALS   #
#       must be used for the correct export of fields containing the tokens   #   
#       and references.                                                       #
#               KEYWORDS:   Keyword tokens only                               #
#               LCX:        Tokens preceding keywords only                    #
#               RCX:        Tokens following keywords only                    #
#               REF:        Reference                                         #
#               TOKENS:     Tokens, if not divided into keywords/context      #
#               UUID:       A unique ID. Essential if annotation will be added#
#                           and re-imported.                                  #
#                                                                             #
# Settings related to the ConllExporter                                       #
# -------------------------------------                                       #
# CE_lemma, CE_cpostag, CE_postag, CE_head, CE_deprel, CE_phead, CE_pdeprel:  #
#       Name of token tag to be written to each column in the Conll file.     #
#       Default values are 'conll_LEMMA', 'conll_CPOSTAG', etc.               #
# CE_feats:                                                                   #
#       List of token tag names to be exported as key=value pairs in the      #
#       FEATS column of the Conll file. If not given, no feats are written.   #
###############################################################################

[exporter]
tok_fmt={0}
tok_delimiter=" "
TE_dialect=excel
TE_header=True
CE_lemma=conll_LEMMA
CE_cpostag=conll_CPOSTAG
CE_postag=conll_POSTAG
CE_head=conll_HEAD
CE_deprel=conll_DEPREL
CE_phead=conll_PHEAD
CE_pdeprel=conll_PDEPREL

[merger]


################################################################################
# Settings in the advanced section of the file should only be altered if you   #
# understand the object attributes in importers.py that are affected!          #
################################################################################
[advanced]
PO_dump_xml=tmp.xml
PO_script_file=conman/scripts/pennout2cnc.py